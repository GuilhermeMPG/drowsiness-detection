{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalar e Importar Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar e importar as dependências necessárias para o projeto, incluindo PyTorch, Torchvision e Torchaudio.\n",
    "# Aqui estamos utilizando o comando pip para instalar as bibliotecas torch, torchvision e torchaudio.\n",
    "# Essas bibliotecas são essenciais para trabalhar com redes neurais profundas e visão computacional.\n",
    "# O parâmetro --index-url especifica o índice de onde os pacotes serão baixados.\n",
    "# Caso você esteja utilizando uma GPU diferente, pode ser necessário alterar a URL para a versão correta do CUDA.\n",
    "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Se necessárias para o projeto.\n",
    "# Clonar o repositório YOLOv5 do GitHub.\n",
    "# O YOLOv5 é uma das arquiteturas mais populares para detecção de objetos em tempo real.\n",
    "# Clonando o repositório, teremos acesso ao código e aos modelos pré-treinados.\n",
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "\n",
    "# Se necessárias para o projeto.\n",
    "# Instalar as dependências listadas no arquivo requirements.txt do repositório YOLOv5.\n",
    "# Essas dependências incluem bibliotecas adicionais necessárias para o funcionamento do YOLOv5.\n",
    "# O comando cd yolov5 navega até o diretório clonado e pip install -r requirements.txt instala as dependências.\n",
    "!cd yolov5 & pip install -r requirements.txt\n",
    "\n",
    "# Importar as bibliotecas necessárias para o projeto.\n",
    "# torch: Biblioteca principal do PyTorch para criação e treinamento de modelos de aprendizado profundo.\n",
    "# matplotlib.pyplot: Biblioteca para criação de gráficos e visualização de dados.\n",
    "# numpy: Biblioteca para manipulação de arrays e operações matemáticas.\n",
    "# cv2: Biblioteca OpenCV para processamento de imagens e vídeos.\n",
    "# os: Biblioteca para interagir com o sistema operacional, como manipulação de arquivos e diretórios.\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de Sonolência com YOLO - TCC de Engenharia de Computação\n",
    "\n",
    "Este repositório contém o código e os arquivos necessários para a aplicação de YOLO (You Only Look Once) em um projeto de TCC de Engenharia de Computação. O objetivo é construir um modelo de detecção de sonolência em automóveis utilizando um Raspberry Pi. O YOLO foi escolhido por ser uma tecnologia otimizada e eficiente para este tipo de equipamento.\n",
    "\n",
    "## Descrição do Projeto\n",
    "\n",
    "A partir de uma base de dados, podemos gerar um modelo que utiliza aprendizado de máquina para a detecção de determinados objetos. Neste repositório, temos um modelo treinado para nossa versão de detecção de fadiga/sonolência através de uma câmera conectada ao Raspberry Pi.\n",
    "\n",
    "Todas as evoluções e melhorias do projeto, visando aumentar a precisão ou não, estão sendo adicionadas dentro da pasta \n",
    "\n",
    "train\n",
    "\n",
    ". A pasta `exp` representa um experimento, e dentro dela existe o arquivo `weights` que contém os modelos treinados. Sempre haverá o `last.pt`, que representa o experimento atual, e o `best.pt`, que é o melhor modelo baseado nos dados.\n",
    "\n",
    "## Base de Dados\n",
    "\n",
    "A base de dados utilizada está disponível no Kaggle no link Kaggle Dataset Link.\n",
    "\n",
    "## Executando e Testando o Processo\n",
    "\n",
    "Para executar e testar o processo, podemos usar o arquivo Jupyter Notebook disponível, seguindo o passo a passo. Para treinar o modelo, é necessário ter uma base de dados. Podemos utilizar os pesos dos treinamentos anteriores ou fazer do zero.\n",
    "\n",
    "### Treinamento do Modelo\n",
    "\n",
    "Para treinar o modelo, utilize o comando:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "!cd yolov5 && python train.py --img 320 --batch 16 --epochs 100 --data dataset.yml --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Utilizando Pesos Treinados\n",
    "\n",
    "Para utilizar os pesos dos treinamentos anteriores, use o comando:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "--weights runs/train/exp/weights/best.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O valor após `--weights` define qual modelo será utilizado.\n",
    "\n",
    "### Estrutura do Arquivo `dataset.yml`\n",
    "\n",
    "Dentro da pasta \n",
    "\n",
    "yolov5\n",
    "\n",
    ", há um arquivo chamado `dataset.yml`, que contém informações sobre os nomes e diretórios das imagens. Ao fazer o treinamento de um modelo, é necessário indicar ali os diretórios corretos.\n",
    "\n",
    "## Arquivos de Extensão `.pt`\n",
    "\n",
    "Os arquivos de extensão `.pt` são modelos treinados. Eles são utilizados para carregar os pesos do modelo durante a inferência ou para continuar o treinamento.\n",
    "\n",
    "## Estrutura do Jupyter Notebook\n",
    "\n",
    "O Jupyter Notebook contém as seguintes seções:\n",
    "\n",
    "1. **Instalar e Importar Dependências**: Instalação das bibliotecas necessárias.\n",
    "2. **Clonar Repositório YOLOv5**: Clonagem do repositório YOLOv5 do GitHub.\n",
    "3. **Instalar Requisitos do YOLOv5**: Instalação das dependências listadas no arquivo `requirements.txt`.\n",
    "4. **Importar Bibliotecas Necessárias**: Importação das bibliotecas essenciais para o projeto.\n",
    "5. **Treinar o Modelo do Zero**: Treinamento do modelo YOLOv5 do zero usando um conjunto de dados personalizado.\n",
    "6. **Carregar Modelo Personalizado**: Carregamento do modelo YOLOv5 personalizado treinado.\n",
    "7. **Carregar Imagem de Teste**: Carregamento de uma imagem de teste para realizar a detecção de objetos.\n",
    "8. **Obter Resultados do Modelo**: Obtenção dos resultados da detecção de objetos na imagem de teste.\n",
    "9. **Exibir Resultados**: Exibição dos resultados da detecção de objetos na imagem de teste usando Matplotlib.\n",
    "10. **Inicializar e Processar Vídeo da Câmera**: Inicialização da câmera e processamento do vídeo em tempo real para detecção de sonolência usando o modelo YOLOv5.\n",
    "\n",
    "## Contribuições\n",
    "\n",
    "Contribuições são bem-vindas! Sinta-se à vontade para abrir issues e pull requests para melhorias e correções.\n",
    "\n",
    "## Licença\n",
    "\n",
    "Este projeto está licenciado sob a MIT License.\n",
    "\n",
    "---\n",
    "\n",
    "Para mais informações, consulte a documentação do YOLOv5 e os tutoriais disponíveis no repositório oficial do [YOLOv5](https://github.com/ultralytics/yolov5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar as bibliotecas necessárias para o projeto.\n",
    "# torch: Biblioteca principal do PyTorch para criação e treinamento de modelos de aprendizado profundo.\n",
    "# matplotlib.pyplot: Biblioteca para criação de gráficos e visualização de dados.\n",
    "# numpy: Biblioteca para manipulação de arrays e operações matemáticas.\n",
    "# cv2: Biblioteca OpenCV para processamento de imagens e vídeos.\n",
    "# os: Biblioteca para interagir com o sistema operacional, como manipulação de arquivos e diretórios.\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar o Modelo do Zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo YOLOv5 do zero usando um conjunto de dados personalizado.\n",
    "# Aqui estamos utilizando o comando para treinar o modelo YOLOv5.\n",
    "# O parâmetro --img especifica o tamanho das imagens de entrada.\n",
    "# O parâmetro --batch define o tamanho do lote para o treinamento.\n",
    "# O parâmetro --epochs define o número de épocas para o treinamento.\n",
    "# O parâmetro --data especifica o arquivo de configuração do conjunto de dados.\n",
    "# O parâmetro --workers define o número de trabalhadores para carregar os dados.\n",
    "# Você pode ajustar esses parâmetros conforme necessário para melhorar o desempenho ou adaptar às suas necessidades.\n",
    "!cd yolov5 && python train.py --img 320 --batch 16 --epochs 100 --data dataset.yml --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Modelo Personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo YOLOv5 personalizado treinado a partir do caminho especificado.\n",
    "# Aqui estamos utilizando a função torch.hub.load para carregar um modelo YOLOv5 personalizado.\n",
    "# O parâmetro 'ultralytics/yolov5' especifica o repositório do modelo.\n",
    "# O parâmetro 'custom' indica que estamos carregando um modelo personalizado.\n",
    "# O parâmetro path define o caminho para o arquivo de pesos do modelo treinado.\n",
    "# O parâmetro force_reload=True força o recarregamento do modelo, garantindo que estamos utilizando a versão mais recente.\n",
    "# Caso você tenha treinado o modelo em um caminho diferente, altere o valor do parâmetro path para o caminho correto.\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp2/weights/last.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Imagem de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar uma imagem de teste para realizar a detecção de objetos.\n",
    "# Aqui estamos utilizando a função os.path.join para construir o caminho completo da imagem de teste.\n",
    "# A imagem será carregada a partir do diretório 'data/test/images'.\n",
    "# Você pode substituir o nome do arquivo de imagem pelo nome da sua imagem de teste.\n",
    "# Certifique-se de que a imagem esteja no diretório especificado ou ajuste o caminho conforme necessário.\n",
    "img = os.path.join('data', 'test', 'images', '2023-09-22-17-51-12_mp4-57_jpg.rf.82c98b433c4add67d74c75bdadaff338.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obter Resultados do Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter os resultados da detecção de objetos na imagem de teste usando o modelo carregado.\n",
    "# Aqui estamos utilizando o modelo YOLOv5 carregado para realizar a detecção de objetos na imagem de teste.\n",
    "# A função model(img) processa a imagem e retorna os resultados da detecção.\n",
    "# Você pode ajustar os parâmetros do modelo ou da imagem conforme necessário para melhorar a precisão ou o desempenho.\n",
    "results = model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exibir Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir os resultados da detecção de objetos na imagem de teste usando Matplotlib.\n",
    "# Aqui estamos utilizando a função %matplotlib inline para garantir que os gráficos sejam exibidos diretamente no notebook.\n",
    "# A função plt.imshow é utilizada para exibir a imagem com os resultados da detecção.\n",
    "# A função np.squeeze é utilizada para remover dimensões de tamanho 1 do array, se necessário.\n",
    "# A função results.render() retorna a imagem com as detecções desenhadas sobre ela.\n",
    "# A função plt.show() exibe a imagem no notebook.\n",
    "%matplotlib inline \n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicializar e Processar Vídeo da Câmera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar a câmera e processar o vídeo em tempo real para detecção de sonolência usando o modelo YOLOv5.\n",
    "# Aqui estamos utilizando a biblioteca OpenCV para capturar o vídeo da câmera.\n",
    "# O índice 1 no cv2.VideoCapture(1) pode ser alterado para 0 ou outro número, dependendo da sua configuração de câmera.\n",
    "# O loop while cap.isOpened() continua enquanto a câmera estiver aberta.\n",
    "# A função cap.read() captura um quadro do vídeo. Se não conseguir capturar, imprime uma mensagem de erro e sai do loop.\n",
    "# O quadro capturado é rotacionado 90 graus no sentido horário usando cv2.rotate.\n",
    "# O modelo YOLOv5 é utilizado para processar o quadro rotacionado e detectar objetos.\n",
    "# A função results.render() desenha as detecções no quadro.\n",
    "# O quadro processado é exibido em uma janela usando cv2.imshow.\n",
    "# O loop é interrompido se a tecla 'q' for pressionada.\n",
    "# No final, a câmera é liberada e todas as janelas OpenCV são fechadas.\n",
    "\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Erro ao capturar o quadro.\")\n",
    "        break\n",
    "\n",
    "    rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    results = model(rotated_frame)\n",
    "    rendered_frame = np.squeeze(results.render())\n",
    "    cv2.imshow('YOLO', rendered_frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
